using MDPs
import MDPs: preexperiment, preepisode, prestep, poststep, postepisode, postexperiment, VectorSpace
using Flux
using Random
using UnPack
using DataStructures
using StatsBase

export DQNLearner

mutable struct DQNLearner{T<:AbstractFloat} <: AbstractHook
    Ï€::DQNPolicy{T}
    Ï::Float32
    min_explore_steps::Int
    train_interval::Int
    batch_size::Int

    s::Union{Vector{T}, Nothing}
    buff::CircularBuffer{Tuple{Vector{T}, Int, Float64, Vector{T}, Bool}}
    qmodelâ€²
    optim::Adam

    function DQNLearner(Ï€::DQNPolicy{T}, Î±; polyak=0.995, min_explore_steps=10000, train_interval=1, batch_size=32, buffer_size=1000000) where T <: AbstractFloat
        buff = CircularBuffer{Tuple{Vector{T}, Int, Float64, Vector{T}, Bool}}(buffer_size)
        new{T}(Ï€, polyak, min_explore_steps, train_interval, batch_size, nothing, buff, deepcopy(Ï€.qmodel), Adam(Î±))
    end
end

function prestep(dqn::DQNLearner; env::AbstractMDP, kwargs...)
    dqn.s = copy(state(env))
end

function poststep(dqn::DQNLearner{T}; env::AbstractMDP{Vector{T}, Int}, steps::Int, rng::AbstractRNG, kwargs...) where T <: AbstractFloat
    @unpack Ï€, Ï, batch_size, s, qmodelâ€² = dqn

    a, r, sâ€², d, Î³ = action(env), reward(env), copy(state(env)), in_absorbing_state(env), discount_factor(env)
    push!(dqn.buff, (s, a, r, sâ€², d))

    if steps >= dqn.min_explore_steps && steps % dqn.train_interval == 0
        replay_batch = rand(rng, dqn.buff, batch_size)
        ğ¬, ğš, ğ«, ğ¬â€², ğ = map(i -> reduce((ğ±, y) -> cat(ğ±, y; dims=ndims(y) + 1), map(experience -> experience[i], replay_batch)), 1:5)
        ğ¬, ğ«, ğ¬â€², ğ = tof32.((ğ¬, ğ«, ğ¬â€², ğ))
        ğš_ğ¬ = map(j -> CartesianIndex(ğš[j], j), 1:batch_size)
        
        Î¸ = Flux.params(Ï€.qmodel)
        â„“, âˆ‡Î¸â„“ = Flux.Zygote.withgradient(Î¸) do
            ğªÌ‚ = Ï€.qmodel(ğ¬)
            ğª = Flux.Zygote.ignore() do
                ğ›‘â€² = Ï€(ğ¬â€², :)
                ğªâ€² = qmodelâ€²(ğ¬â€²)
                ğ¯â€² = sum(ğ›‘â€² .* ğªâ€², dims=1)[1, :]
                ğ›… = zeros(Float32, size(ğªÌ‚)) # TD error
                ğ›…[ğš_ğ¬] = ğ« + (1 .- ğ) * Float32(Î³) .* ğ¯â€² - @view ğªÌ‚[ğš_ğ¬]
                ğªÌ‚ + ğ›…
            end
            Flux.mse(ğªÌ‚, ğª)
        end

        Flux.update!(dqn.optim, Î¸, âˆ‡Î¸â„“)

        Î¸â€² = Flux.params(qmodelâ€²)
        Flux.loadparams!(qmodelâ€², Ï .* Î¸â€² .+ (1 - Ï) .* Î¸)

        if steps % 1000 == 0
            vÌ„ = mean(sum(Ï€(ğ¬, :) .* Ï€.qmodel(ğ¬), dims=1))
            @info "learning stats" steps â„“ vÌ„
        end
    end
    nothing
end
