using MDPs
import MDPs: preexperiment, preepisode, prestep, poststep, postepisode, postexperiment, VectorSpace
using Flux
using Random
using UnPack
using DataStructures
using StatsBase
using Flux: Optimiser, ClipNorm, ClipValue

export DQNLearner

Base.@kwdef mutable struct DQNLearner{T<:AbstractFloat} <: AbstractHook
    Ï€::DQNPolicy{T}
    Î·::Float32 = 0.0001
    Î³::Float32 = 0.99
    Ï::Float32 = 0.999
    min_explore_steps::Int = 10000
    train_interval::Int = 1
    gradsteps::Int = 1
    batch_size::Int = 32
    buffer_size::Int = 1000000
    clipnorm = Inf
    clipval = Inf
    device = cpu

    s::Union{Vector{T}, Nothing} = nothing
    buff::CircularBuffer{Tuple{Vector{T}, Int, Float64, Vector{T}, Bool}} = CircularBuffer{Tuple{Vector{T}, Int, Float64, Vector{T}, Bool}}(buffer_size)
    Ï€_gpu::DQNPolicy{T} = device(deepcopy(Ï€))
    qmodelâ€² = device(deepcopy(Ï€.qmodel))
    optim = clipnorm < Inf ? Optimiser(ClipNorm(clipnorm), Adam(Î·)) : (clipval < Inf ? Optimiser(ClipValue(clipval), Adam(Î·)) : Adam(Î·))
    stats::Dict{Symbol, Float32} = Dict{Symbol, Float32}()
end

function prestep(dqn::DQNLearner; env::AbstractMDP, kwargs...)
    dqn.s = copy(state(env))
end

function poststep(dqn::DQNLearner{T}; env::AbstractMDP{Vector{T}, Int}, steps::Int, rng::AbstractRNG, returns, kwargs...) where T <: AbstractFloat
    @unpack Ï€_gpu, Î³, Ï, batch_size, s, qmodelâ€², device = dqn

    a, r, sâ€², d = action(env), reward(env), copy(state(env)), in_absorbing_state(env)
    push!(dqn.buff, (s, a, r, sâ€², d))

    if steps >= dqn.min_explore_steps && steps % dqn.train_interval == 0
        for gradstep in 1:dqn.gradsteps
            replay_batch = rand(rng, dqn.buff, batch_size)
            ğ¬, ğš, ğ«, ğ¬â€², ğ = map(i -> reduce((ğ±, y) -> cat(ğ±, y; dims=ndims(y) + 1), map(experience -> experience[i], replay_batch)), 1:5)
            ğ¬, ğ«, ğ¬â€², ğ = (ğ¬, ğ«, ğ¬â€², ğ) .|> tof32 .|> device
            ğš_ğ¬ = map(j -> CartesianIndex(ğš[j], j), 1:batch_size) |> device
            
            Î¸ = Flux.params(Ï€_gpu.qmodel)
            â„“, âˆ‡Î¸â„“ = Flux.Zygote.withgradient(Î¸) do
                ğªÌ‚ = Ï€_gpu.qmodel(ğ¬)
                ğª = Flux.Zygote.ignore() do
                    ğ›‘â€² = Ï€_gpu(ğ¬â€², :)
                    ğªâ€² = qmodelâ€²(ğ¬â€²)
                    ğ¯â€² = sum(ğ›‘â€² .* ğªâ€², dims=1)[1, :]
                    ğ›… = zeros(Float32, size(ğªÌ‚)) |> device # TD error
                    # println(size(ğ›…))
                    ğ›…[ğš_ğ¬] = ğ« + (1 .- ğ) * Î³ .* ğ¯â€² - @view ğªÌ‚[ğš_ğ¬]
                    ğªÌ‚ + ğ›…
                end
                Flux.mse(ğªÌ‚, ğª)
            end

            Flux.update!(dqn.optim, Î¸, âˆ‡Î¸â„“)

            vÌ„ = mean(sum(Ï€_gpu(ğ¬, :) .* Ï€_gpu.qmodel(ğ¬), dims=1))
            dqn.stats[:vÌ„] = vÌ„
            dqn.stats[:â„“] = â„“
        end

        Î¸ = Flux.params(Ï€_gpu.qmodel)
        Î¸â€² = Flux.params(qmodelâ€²)
        for (param, paramâ€²) in zip(Î¸, Î¸â€²)
            copy!(paramâ€², Ï * paramâ€² + (1 - Ï) * param)
        end

        if device == gpu
            Î¸ = Flux.params(Ï€_gpu.qmodel)
            Î¸cpu = Flux.params(dqn.Ï€.qmodel)
            for (param, param_cpu) in zip(Î¸, Î¸cpu)
                copy!(param_cpu, param)
            end
        end

        if steps % 1000 == 0
            episodes = length(returns)
            @debug "learning stats" steps episodes dqn.stats...
        end
    end
    nothing
end
